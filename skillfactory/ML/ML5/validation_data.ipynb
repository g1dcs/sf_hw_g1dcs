{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Валидация данных\n",
    "## <center> Методы валидации данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Павел\\AppData\\Local\\Temp\\ipykernel_26860\\3755730.py:10: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn') #стиль отрисовки seaborn\n"
     ]
    }
   ],
   "source": [
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    " \n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import model_selection #методы разделения и валидации\n",
    "from sklearn import linear_model #линейные модели\n",
    "from sklearn import tree #деревья решений\n",
    "plt.style.use('seaborn') #стиль отрисовки seaborn\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ph</th>\n",
       "      <th>Hardness</th>\n",
       "      <th>Solids</th>\n",
       "      <th>Chloramines</th>\n",
       "      <th>Sulfate</th>\n",
       "      <th>Conductivity</th>\n",
       "      <th>Organic_carbon</th>\n",
       "      <th>Trihalomethanes</th>\n",
       "      <th>Turbidity</th>\n",
       "      <th>Potability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>204.890455</td>\n",
       "      <td>20791.318981</td>\n",
       "      <td>7.300212</td>\n",
       "      <td>368.516441</td>\n",
       "      <td>564.308654</td>\n",
       "      <td>10.379783</td>\n",
       "      <td>86.990970</td>\n",
       "      <td>2.963135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.716080</td>\n",
       "      <td>129.422921</td>\n",
       "      <td>18630.057858</td>\n",
       "      <td>6.635246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>592.885359</td>\n",
       "      <td>15.180013</td>\n",
       "      <td>56.329076</td>\n",
       "      <td>4.500656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.099124</td>\n",
       "      <td>224.236259</td>\n",
       "      <td>19909.541732</td>\n",
       "      <td>9.275884</td>\n",
       "      <td>NaN</td>\n",
       "      <td>418.606213</td>\n",
       "      <td>16.868637</td>\n",
       "      <td>66.420093</td>\n",
       "      <td>3.055934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.316766</td>\n",
       "      <td>214.373394</td>\n",
       "      <td>22018.417441</td>\n",
       "      <td>8.059332</td>\n",
       "      <td>356.886136</td>\n",
       "      <td>363.266516</td>\n",
       "      <td>18.436524</td>\n",
       "      <td>100.341674</td>\n",
       "      <td>4.628771</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.092223</td>\n",
       "      <td>181.101509</td>\n",
       "      <td>17978.986339</td>\n",
       "      <td>6.546600</td>\n",
       "      <td>310.135738</td>\n",
       "      <td>398.410813</td>\n",
       "      <td>11.558279</td>\n",
       "      <td>31.997993</td>\n",
       "      <td>4.075075</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ph    Hardness        Solids  Chloramines     Sulfate  Conductivity  \\\n",
       "0       NaN  204.890455  20791.318981     7.300212  368.516441    564.308654   \n",
       "1  3.716080  129.422921  18630.057858     6.635246         NaN    592.885359   \n",
       "2  8.099124  224.236259  19909.541732     9.275884         NaN    418.606213   \n",
       "3  8.316766  214.373394  22018.417441     8.059332  356.886136    363.266516   \n",
       "4  9.092223  181.101509  17978.986339     6.546600  310.135738    398.410813   \n",
       "\n",
       "   Organic_carbon  Trihalomethanes  Turbidity  Potability  \n",
       "0       10.379783        86.990970   2.963135           0  \n",
       "1       15.180013        56.329076   4.500656           0  \n",
       "2       16.868637        66.420093   3.055934           0  \n",
       "3       18.436524       100.341674   4.628771           0  \n",
       "4       11.558279        31.997993   4.075075           0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# загрузим данные и прочтем датасет\n",
    "water_data = pd.read_csv('../data/water_potability.csv')\n",
    "water_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполним пропуски медианным значением\n",
    "water_data['ph'] = water_data['ph'].fillna(water_data.groupby('Potability')['ph'].transform('median'))\n",
    "water_data['Sulfate'] = water_data['Sulfate'].fillna(water_data.groupby('Potability')['Sulfate'].transform('median'))\n",
    "water_data['Trihalomethanes'] = water_data['Trihalomethanes'].fillna(water_data.groupby('Potability')['Trihalomethanes'].transform('median'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ph                 0.0\n",
       "Hardness           0.0\n",
       "Solids             0.0\n",
       "Chloramines        0.0\n",
       "Sulfate            0.0\n",
       "Conductivity       0.0\n",
       "Organic_carbon     0.0\n",
       "Trihalomethanes    0.0\n",
       "Turbidity          0.0\n",
       "Potability         0.0\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(water_data.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим данные на матрицу и вектор ответов\n",
    "X = water_data.drop('Potability', axis=1)\n",
    "y = water_data['Potability']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Методы валидации данных\n",
    "#### Метод Hold-Out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если мы используем двухкомпонентный подход (разбиваем выборку на тренировочную и валидационную, она же тестовая), то всё очень просто: нам лишь нужно вызвать функцию train_test_split() и передать в неё матрицу наблюдений X и вектор-столбец с правильными ответами y.\n",
    "\n",
    "Для примера разделим выборку в соотношении 80/20 (test_size=0.2), в качестве значения параметра random_state по традиции возьмём число 42.\n",
    "\n",
    "Функция вернёт четыре массива:\n",
    "\n",
    "- таблицу X с обучающими примерами,\n",
    "- таблицу X с примерами для валидации,\n",
    "- столбец y с ответами на обучающие примеры,\n",
    "- столбец y с ответами на валидационные примеры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (656, 9)\n"
     ]
    }
   ],
   "source": [
    "# Проверим размер полученных выборок\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итак, 2 620 образцов воды являются обучающими — в них модель будет искать закономерности и подбирать внутренние параметры, а 656 являются валидационными — на них мы будем производить контроль качества.\n",
    "\n",
    "Далее нам останется только обучить модель на тренировочной выборке (X_train, y_train) и рассчитать метрики на валидационной выборке (X_valid, y_valid).\n",
    "\n",
    "В качестве модели будем использовать дерево решений с максимальной глубиной 7, энтропией в качестве критерия информативности, минимальное число объектов в листе дерева — 5.\n",
    "\n",
    "После обучения сделаем предсказание для каждой из выборок и рассчитаем метрику. В качестве метрики для простоты возьмём долю правильных ответов — accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train hold-out accuracy: 0.82\n",
      "Valid hold-out accuracy: 0.77\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    "#Обучаем модель на тренировочной выборке\n",
    "model.fit(X_train, y_train)\n",
    "#Делаем предсказание для каждой из выборок\n",
    "y_train_pred = model.predict(X_train)\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "#Выводим значения метрик\n",
    "print('Train hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_train, y_train_pred)))\n",
    "print('Valid hold-out accuracy: {:.2f}'.format(metrics.accuracy_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбиение данных на трехкомпонентные выборки\n",
    "Если же мы используем трёхкомпонентный подход (разбиваем выборку на тренировочную, валидационную и отдельную тестовую), тут нам понадобится чуть больше кода. К сожалению, в sklearn нет специализированного функционала для такого разбиения.\n",
    "\n",
    "Применим функцию train_test_split() дважды: сначала разобьём исходный набор на тренировочный и валидационный в соотношении 80/20, затем разобьём валидационный набор на валидационный и тестовый в соотношении 50/50. В итоге наша выборка будет разбита в соотношении 80/10/10:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (2620, 9)\n",
      "Valid shape: (328, 9)\n",
      "Test shape: (328, 9)\n"
     ]
    }
   ],
   "source": [
    "#разбиваем исходную выборку на тренировочную и валидационную в соотношении 80/20\n",
    "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = model_selection.train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
    "\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation\n",
    "Метод k-fold более известен как кросс-валидация (cross validation), или перекрёстный контроль."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта класса KFold есть метод split(). В данный метод необходимо передать матрицу наблюдений X и вектор-столбец ответов y — метод вернёт генератор, который позволит получать индексы тренировочной и валидационной выборок, сгенерированных по методу k-fold.\n",
    "\n",
    "Будем использовать двухкомпонентный контроль, то есть подавать в кросс-валидацию весь доступный набор данных без предварительного выделения тестовой выборки.\n",
    "\n",
    "Создадим объект KFold для кросс-валидации с пятью фолдами, остальные параметры оставим по умолчанию. Затем организуем цикл for для получения элементов из генератора, созданного с помощью метода split(). На каждой итерации в переменных train_index и valid_index будут находиться индексы текущей тренировочной и валидационной выборок соответственно.\n",
    "\n",
    "В цикле будем:\n",
    "\n",
    "- выделять строки таблицы, относящиеся к текущим тренировочной и валидационной выборкам, в отдельные таблицы;\n",
    "- обучать дерево решений;\n",
    "- делать предсказания для текущих тренировочной и валидационной выборок;\n",
    "- рассчитывать метрику accuracy на текущих выборках и заносить её значение в список.\n",
    "\n",
    "Код будет выглядеть следующим образом:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8034351145038168, 0.8168637924456315, 0.8027470431133156, 0.8267836703548264, 0.8157191911484166]\n",
      "[0.7957317073170732, 0.7053435114503817, 0.7358778625954199, 0.7282442748091603, 0.732824427480916]\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    "#Создаём список для хранения тренировочных и валидационных метрик\n",
    "train_metrics = []\n",
    "val_metrics = []\n",
    "#Организуем цикл для кросс-валидации (используем весь набор данных)\n",
    "#train_index — индексы тренировочной выборки\n",
    "#valid_index — индексы валидационной выборки\n",
    "for train_index, valid_index in kf.split(X, y): \n",
    "    #Создаём тренировочную и валидационную выборку, обращаясь по текущим индексам\n",
    "    X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "    X_valid, y_valid = X.iloc[valid_index], y.iloc[valid_index]\n",
    "    #Обучаем случайный лес на тренировочной выборке\n",
    "    model.fit(X_train, y_train)\n",
    "    #Делаем предсказание для каждой из выборок\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    #Рассчитываем метрику и заносим её в список\n",
    "    train_metrics.append(metrics.accuracy_score(y_train, y_train_pred))\n",
    "    val_metrics.append(metrics.accuracy_score(y_valid, y_valid_pred))\n",
    "    \n",
    "print(train_metrics)\n",
    "print(val_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(train_metrics)))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(val_metrics)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На самом деле весь приведённый выше код можно значительно сократить, если использовать специальную функцию для кросс-валидации — cross_validate() из модуля model_selection. Она организует процедуру кросс-валидации и расчёт метрик."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03287601, 0.04848409, 0.03207707, 0.02402234, 0.03224659]),\n",
       " 'score_time': array([0.00825238, 0.        , 0.        , 0.0079999 , 0.00819731]),\n",
       " 'test_score': array([0.79573171, 0.70534351, 0.73587786, 0.72824427, 0.73282443]),\n",
       " 'train_score': array([0.80343511, 0.81686379, 0.80274704, 0.82678367, 0.81571919])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Создаём объект кросс-валидатора KFold\n",
    "kf = model_selection.KFold(n_splits=5)\n",
    " \n",
    "#Считаем метрики на кросс-валидации k-fold\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X, #матрица наблюдений X\n",
    "    y=y, #вектор ответов y\n",
    "    cv=kf, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    "display(cv_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.81\n",
      "Valid k-fold mean accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leave-one-out cross-validation\n",
    "Метод leave-one-out (отложенный пример), или поэлементная кросс-валидация — это частный случай кросс-валидации (k-fold), когда размер $k$ равняется размеру всей выборки $k=n$ , где n — количество примеров (строк в таблице)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В библиотеке sklearn метод leave-one-out реализован в классе LeaveOneOut. Параметров инициализации у данного класса нет.\n",
    "\n",
    "Работа с кросс-валидатором полностью идентична работе с KFold, который мы рассматривали ранее (цикл для организации кросс-валидации вручную будет выглядеть аналогично).\n",
    "\n",
    "Объект класса LeaveOneOut также можно передать в функцию cross_validate() для получения метрик на каждом из примеров. В случае с метрикой accuracy список будет состоять из 0 и 1 (0 — модель не угадала класс на отложенном примере, 1 — модель угадала класс на отложенном примере).\n",
    "\n",
    "Так как датасет у нас довольно большой (более трёх тысяч образцов воды), алгоритм кросс-валидации leave-one-out будет выполняться очень долго. Для экономии времени выполнения кода будем использовать первые 500 наблюдений из исходной таблицы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train k-fold mean accuracy: 0.95\n",
      "Valid k-fold mean accuracy: 0.90\n"
     ]
    }
   ],
   "source": [
    "#Создаём модель\n",
    "model = tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', #критерий информативности\n",
    "    max_depth=7, #максимальная глубина\n",
    "    min_samples_leaf=5, #минимальное число объектов в листе\n",
    "    random_state=42 #генератор случайных чисел  \n",
    ")\n",
    " \n",
    "#Создаём кросс-валидатор LeaveOneOut\n",
    "loo = model_selection.LeaveOneOut()\n",
    " \n",
    "#Считаем метрики на кросс-валидации leave-one-out\n",
    "cv_metrics = model_selection.cross_validate(\n",
    "    estimator=model, #модель\n",
    "    X=X.iloc[:500], #матрица наблюдений X\n",
    "    y=y.iloc[:500], #вектор ответов y\n",
    "    cv=loo, #кросс-валидатор\n",
    "    scoring='accuracy', #метрика\n",
    "    return_train_score=True #подсчёт метрики на тренировочных фолдах\n",
    ")\n",
    " \n",
    "print('Train k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['train_score'])))\n",
    "print('Valid k-fold mean accuracy: {:.2f}'.format(np.mean(cv_metrics['test_score'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
