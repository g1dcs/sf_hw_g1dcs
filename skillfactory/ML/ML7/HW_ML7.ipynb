{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> HW for ML-7"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Необходимо предсказать биологический ответ молекул (столбец 'Activity') по их химическому составу (столбцы D1-D1776).\n",
    "\n",
    "\n",
    "Данные представлены в формате CSV.  Каждая строка представляет молекулу. \n",
    "\n",
    "- Первый столбец Activity содержит экспериментальные данные, описывающие фактический биологический ответ [0, 1]; \n",
    "- Остальные столбцы D1-D1776 представляют собой молекулярные дескрипторы — это вычисляемые свойства, которые могут фиксировать некоторые характеристики молекулы, например размер, форму или состав элементов."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предварительная обработка не требуется, данные уже закодированы и нормализованы.\n",
    "\n",
    "В качестве метрики будем использовать **F1-score**.\n",
    "\n",
    "Необходимо обучить две модели: логистическую регрессию и случайный лес. Далее нужно сделать подбор гиперпараметров с помощью базовых и продвинутых методов оптимизации. Важно использовать все четыре метода (GridSeachCV, RandomizedSearchCV, Hyperopt, Optuna) хотя бы по разу, максимальное количество итераций **не должно превышать 50**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Павел\\AppData\\Local\\Temp\\ipykernel_9352\\2413690768.py:27: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn')\n"
     ]
    }
   ],
   "source": [
    "#импорт библиотек\n",
    "import numpy as np #для матричных вычислений\n",
    "import pandas as pd #для анализа и предобработки данных\n",
    "import matplotlib.pyplot as plt #для визуализации\n",
    "import seaborn as sns #для визуализации\n",
    "\n",
    "from sklearn import linear_model #линейные моделиё\n",
    "from sklearn import tree #деревья решений\n",
    "from sklearn import ensemble #ансамбли\n",
    "from sklearn import metrics #метрики\n",
    "from sklearn import preprocessing #предобработка\n",
    "from sklearn.model_selection import train_test_split #сплитование выборки\n",
    "from sklearn.model_selection import GridSearchCV # метод для подбора гиперпараметров\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "#делаем импорт hyperplot\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import hyperopt\n",
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "# fmin - основная функция, она будет минимизировать наш функционал\n",
    "# tpe - алгоритм оптимизации\n",
    "# hp - включает набор методов для объявления пространства поиска гиперпараметров\n",
    "# trails - используется для логирования результатов\n",
    "# импортируем optuna\n",
    "import optuna\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.497009</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.132956</td>\n",
       "      <td>0.678031</td>\n",
       "      <td>0.273166</td>\n",
       "      <td>0.585445</td>\n",
       "      <td>0.743663</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.606291</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111209</td>\n",
       "      <td>0.803455</td>\n",
       "      <td>0.106105</td>\n",
       "      <td>0.411754</td>\n",
       "      <td>0.836582</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.480124</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.209791</td>\n",
       "      <td>0.610350</td>\n",
       "      <td>0.356453</td>\n",
       "      <td>0.517720</td>\n",
       "      <td>0.679051</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.196344</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.235606</td>\n",
       "      <td>0.288764</td>\n",
       "      <td>0.805110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.517794</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494734</td>\n",
       "      <td>0.781422</td>\n",
       "      <td>0.154361</td>\n",
       "      <td>0.303809</td>\n",
       "      <td>0.812646</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Activity        D1        D2    D3   D4        D5        D6        D7  \\\n",
       "0         1  0.000000  0.497009  0.10  0.0  0.132956  0.678031  0.273166   \n",
       "1         1  0.366667  0.606291  0.05  0.0  0.111209  0.803455  0.106105   \n",
       "2         1  0.033300  0.480124  0.00  0.0  0.209791  0.610350  0.356453   \n",
       "3         1  0.000000  0.538825  0.00  0.5  0.196344  0.724230  0.235606   \n",
       "4         0  0.100000  0.517794  0.00  0.0  0.494734  0.781422  0.154361   \n",
       "\n",
       "         D8        D9  ...  D1767  D1768  D1769  D1770  D1771  D1772  D1773  \\\n",
       "0  0.585445  0.743663  ...      0      0      0      0      0      0      0   \n",
       "1  0.411754  0.836582  ...      1      1      1      1      0      1      0   \n",
       "2  0.517720  0.679051  ...      0      0      0      0      0      0      0   \n",
       "3  0.288764  0.805110  ...      0      0      0      0      0      0      0   \n",
       "4  0.303809  0.812646  ...      0      0      0      0      0      0      0   \n",
       "\n",
       "   D1774  D1775  D1776  \n",
       "0      0      0      0  \n",
       "1      0      1      0  \n",
       "2      0      0      0  \n",
       "3      0      0      0  \n",
       "4      0      0      0  \n",
       "\n",
       "[5 rows x 1777 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузим данные и проверим их на читаемость\n",
    "data = pd.read_csv('../data/_train_sem09 (1).csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity</th>\n",
       "      <th>D1</th>\n",
       "      <th>D2</th>\n",
       "      <th>D3</th>\n",
       "      <th>D4</th>\n",
       "      <th>D5</th>\n",
       "      <th>D6</th>\n",
       "      <th>D7</th>\n",
       "      <th>D8</th>\n",
       "      <th>D9</th>\n",
       "      <th>...</th>\n",
       "      <th>D1767</th>\n",
       "      <th>D1768</th>\n",
       "      <th>D1769</th>\n",
       "      <th>D1770</th>\n",
       "      <th>D1771</th>\n",
       "      <th>D1772</th>\n",
       "      <th>D1773</th>\n",
       "      <th>D1774</th>\n",
       "      <th>D1775</th>\n",
       "      <th>D1776</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "      <td>3751.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.542255</td>\n",
       "      <td>0.076948</td>\n",
       "      <td>0.592436</td>\n",
       "      <td>0.068142</td>\n",
       "      <td>0.038990</td>\n",
       "      <td>0.212112</td>\n",
       "      <td>0.686653</td>\n",
       "      <td>0.274713</td>\n",
       "      <td>0.455133</td>\n",
       "      <td>0.749517</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026926</td>\n",
       "      <td>0.014663</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>0.021861</td>\n",
       "      <td>0.015196</td>\n",
       "      <td>0.016796</td>\n",
       "      <td>0.012263</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.020261</td>\n",
       "      <td>0.011197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498278</td>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.105860</td>\n",
       "      <td>0.078414</td>\n",
       "      <td>0.115885</td>\n",
       "      <td>0.102592</td>\n",
       "      <td>0.078702</td>\n",
       "      <td>0.090017</td>\n",
       "      <td>0.162731</td>\n",
       "      <td>0.071702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161889</td>\n",
       "      <td>0.120215</td>\n",
       "      <td>0.116938</td>\n",
       "      <td>0.146249</td>\n",
       "      <td>0.122348</td>\n",
       "      <td>0.128522</td>\n",
       "      <td>0.110074</td>\n",
       "      <td>0.107683</td>\n",
       "      <td>0.140911</td>\n",
       "      <td>0.105236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.282128</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.137873</td>\n",
       "      <td>0.006130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.275590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.517811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.138118</td>\n",
       "      <td>0.625627</td>\n",
       "      <td>0.207374</td>\n",
       "      <td>0.378062</td>\n",
       "      <td>0.707339</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.585989</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.190926</td>\n",
       "      <td>0.674037</td>\n",
       "      <td>0.277845</td>\n",
       "      <td>0.499942</td>\n",
       "      <td>0.738961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.668395</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.261726</td>\n",
       "      <td>0.740663</td>\n",
       "      <td>0.335816</td>\n",
       "      <td>0.569962</td>\n",
       "      <td>0.788177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964381</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994735</td>\n",
       "      <td>0.790831</td>\n",
       "      <td>0.989870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1777 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Activity           D1           D2           D3           D4  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.542255     0.076948     0.592436     0.068142     0.038990   \n",
       "std       0.498278     0.079989     0.105860     0.078414     0.115885   \n",
       "min       0.000000     0.000000     0.282128     0.000000     0.000000   \n",
       "25%       0.000000     0.033300     0.517811     0.000000     0.000000   \n",
       "50%       1.000000     0.066700     0.585989     0.050000     0.000000   \n",
       "75%       1.000000     0.100000     0.668395     0.100000     0.000000   \n",
       "max       1.000000     1.000000     0.964381     0.950000     1.000000   \n",
       "\n",
       "                D5           D6           D7           D8           D9  ...  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  ...   \n",
       "mean      0.212112     0.686653     0.274713     0.455133     0.749517  ...   \n",
       "std       0.102592     0.078702     0.090017     0.162731     0.071702  ...   \n",
       "min       0.002630     0.137873     0.006130     0.000000     0.275590  ...   \n",
       "25%       0.138118     0.625627     0.207374     0.378062     0.707339  ...   \n",
       "50%       0.190926     0.674037     0.277845     0.499942     0.738961  ...   \n",
       "75%       0.261726     0.740663     0.335816     0.569962     0.788177  ...   \n",
       "max       1.000000     0.994735     0.790831     0.989870     1.000000  ...   \n",
       "\n",
       "             D1767        D1768        D1769        D1770        D1771  \\\n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000   \n",
       "mean      0.026926     0.014663     0.013863     0.021861     0.015196   \n",
       "std       0.161889     0.120215     0.116938     0.146249     0.122348   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "             D1772        D1773        D1774        D1775        D1776  \n",
       "count  3751.000000  3751.000000  3751.000000  3751.000000  3751.000000  \n",
       "mean      0.016796     0.012263     0.011730     0.020261     0.011197  \n",
       "std       0.128522     0.110074     0.107683     0.140911     0.105236  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 1777 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "display(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3000, 1776)\n",
      "Valid shape: (375, 1776)\n",
      "Test shape: (376, 1776)\n"
     ]
    }
   ],
   "source": [
    "# Зададим вектор у и матрицу X\n",
    "X = data.drop(['Activity'], axis = 1)\n",
    "y = data['Activity']\n",
    "\n",
    "# Разобъем данные на тренировочную, тестовую и валидационную выборки\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size =0.2, stratify=y, random_state =42)\n",
    "#разбиваем валидационную выборку на валидационную и тестовую в соотношении 50/50\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, random_state=42)\n",
    "print('Train shape: {}'.format(X_train.shape))\n",
    "print('Valid shape: {}'.format(X_valid.shape))\n",
    "print('Test shape: {}'.format(X_test.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "1    0.542333\n",
      "0    0.457667\n",
      "Name: Activity, dtype: float64\n",
      "Test:\n",
      "1    0.545213\n",
      "0    0.454787\n",
      "Name: Activity, dtype: float64\n",
      "Valid:\n",
      "1    0.538667\n",
      "0    0.461333\n",
      "Name: Activity, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# проверим распределение целевого признакак в выборках\n",
    "print('Train:\\n', y_train.value_counts(normalize=True), sep='')\n",
    "print('Test:\\n', y_test.value_counts(normalize=True), sep='')\n",
    "print('Valid:\\n' , y_valid.value_counts(normalize=True), sep='')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально обучим модель логистической регрессии и деревьев решения без подбора гиперпараметров, чтобы посмотреть на результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на валидационном наборе: 0.76\n",
      "f1_score на валидационном наборе: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Создадим объект класса логистической регрессии регрессии с параметрами по умолчанию\n",
    "log_reg = linear_model.LogisticRegression(max_iter=50, random_state=42)\n",
    "# train model\n",
    "log_reg.fit(X_train, y_train)\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(log_reg.score(X_valid, y_valid)))\n",
    "y_valid_pred = log_reg.predict(X_valid)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy на валидационном наборе: 0.79\n",
      "f1_score на валидационном наборе: 0.78\n"
     ]
    }
   ],
   "source": [
    "# создадим объект класса случайного леса\n",
    "rf_ml = ensemble.RandomForestClassifier(random_state=42)\n",
    "rf_ml.fit(X_train, y_train)\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(rf_ml.score(X_valid, y_valid)))\n",
    "y_valid_pred = log_reg.predict(X_valid)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом обе модели справляются с задачей неплохо, на валидационной выборке показывают одинаковые результаты на метрики *F_1* = 0.78"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "              {'penalty': ['l2', 'none'] , # тип регуляризации\n",
    "              'solver': ['lbfgs', 'sag'], # алгоритм оптимизации\n",
    "               'C': [0.01, 0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.6, 0.7, 0.9, 1]}, # уровень силы регурялизации\n",
    "              \n",
    "              {'penalty': ['l1', 'l2'] ,\n",
    "              'solver': ['liblinear', 'saga'],\n",
    "               'C': [0.01, 0.1, 0.2, 0.3, 0.4, 0.45, 0.5, 0.6, 0.7, 0.9, 1]}\n",
    "]\n",
    "lr_model = linear_model.LogisticRegression(random_state=1, max_iter=50)\n",
    "rf_model = ensemble.RandomForestClassifier(random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.86 s\n",
      "Wall time: 2min 54s\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'C': 0.2, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# зададим сетку гиперпараметров\n",
    "grid_search_1 = GridSearchCV(\n",
    "    estimator= lr_model, \n",
    "    param_grid=param_grid, \n",
    "    cv=10, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_1.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_1.score(X_valid, y_valid)))\n",
    "y_test_pred = grid_search_1.predict(X_valid)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_test_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_1.best_params_))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим гиперпараметры через RandomizeSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.89 s\n",
      "Wall time: 1min 52s\n",
      "accuracy на тестовом наборе: 0.76\n",
      "f1_score на тестовом наборе: 0.79\n",
      "Наилучшие значения гиперпараметров: {'solver': 'saga', 'penalty': 'l1', 'C': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "grid_search_2 = RandomizedSearchCV(\n",
    "    estimator= lr_model, \n",
    "    param_distributions=param_grid, \n",
    "    cv=10, \n",
    "    n_iter=50,\n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_2.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_2.score(X_valid, y_valid)))\n",
    "y_test_pred_2 = grid_search_2.predict(X_valid)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_test_pred_2)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_2.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим методы сетки и рандомного поиска на RandomForestClassifire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 14 s\n",
      "Wall time: 14min 46s\n",
      "accuracy на валидационном наборе: 0.79\n",
      "f1_score на валидационном наборе: 0.81\n",
      "Наилучшие значения гиперпараметров: {'max_depth': 31, 'min_samples_leaf': 2, 'n_estimators': 120}\n"
     ]
    }
   ],
   "source": [
    "param_distributions_rf = {'n_estimators': list(range(40, 200, 40)),\n",
    "              'min_samples_leaf': list(range(1, 5, 1)),\n",
    "              'max_depth': list(np.linspace(20, 40, 10, dtype=int))\n",
    "              }\n",
    "grid_search_3 = GridSearchCV(\n",
    "    estimator= rf_model, \n",
    "    param_grid=param_distributions_rf, \n",
    "    cv=5, \n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_3.fit(X_train, y_train) \n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(grid_search_3.score(X_valid, y_valid)))\n",
    "y_valid_pred = grid_search_3.predict(X_valid)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_3.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 13.3 s\n",
      "Wall time: 11min 29s\n",
      "accuracy на тестовом наборе: 0.77\n",
      "f1_score на тестовом наборе: 0.80\n",
      "Наилучшие значения гиперпараметров: {'n_estimators': 120, 'min_samples_leaf': 3, 'max_depth': 33}\n"
     ]
    }
   ],
   "source": [
    "grid_search_4 = RandomizedSearchCV(\n",
    "    estimator= rf_model, \n",
    "    param_distributions=param_distributions_rf, \n",
    "    cv=10, \n",
    "    n_iter=50,\n",
    "    n_jobs = -1\n",
    ")  \n",
    "%time grid_search_4.fit(X_train, y_train) \n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(grid_search_4.score(X_valid, y_valid)))\n",
    "y_test_pred_2 = grid_search_4.predict(X_valid)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_test_pred_2)))\n",
    "print(\"Наилучшие значения гиперпараметров: {}\".format(grid_search_4.best_params_))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнив два обычных метода, можем сделать вывод о том, что метрики удалось увелисить, чуть лучше в нашем случае получилось на случайном лесе, но не значительно, если поиграться с параметрами и кросс валидацией их сожно сравнять"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же найдем параметры при помоши методов optuna/hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Зададим списки параметров для моделей\n",
    "space_lr = {'C': hp.lognormal('LR_C', 0, 1.0),\n",
    "       'solver': hp.choice('solver', ['liblinear', 'saga'])\n",
    "       }\n",
    "space_rf={'n_estimators': hp.quniform('n_estimators', 100, 200, 1),\n",
    "       'max_depth' : hp.quniform('max_depth', 15, 26, 1),\n",
    "       'min_samples_leaf': hp.quniform('min_samples_leaf', 2, 10, 1)\n",
    "      }"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "100%|██████████| 20/20 [08:13<00:00, 24.67s/trial, best loss: -0.8160803811393121]\n",
      "Наилучшие значения гиперпараметров {'max_depth': 18.0, 'min_samples_leaf': 2.0, 'n_estimators': 103.0}\n",
      "f1_score на обучающем наборе: 0.99\n",
      "accuracy на валидационном наборе: 0.79\n",
      "f1_score на валидационном наборе: 0.81\n"
     ]
    }
   ],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_rf(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'n_estimators': int(params['n_estimators']), \n",
    "              'max_depth': int(params['max_depth']), \n",
    "             'min_samples_leaf': int(params['min_samples_leaf'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = ensemble.RandomForestClassifier(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # кросс-валидация\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score\n",
    "\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "%time\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_rf, # наша функция \n",
    "          space=space_rf, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "\n",
    "# рассчитаем точность для тестовой выборки\n",
    "model_rf = ensemble.RandomForestClassifier(\n",
    "    random_state=random_state, \n",
    "    n_estimators=int(best['n_estimators']),\n",
    "    max_depth=int(best['max_depth']),\n",
    "    min_samples_leaf=int(best['min_samples_leaf'])\n",
    ")\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_train_pred = model_rf.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(model_rf.score(X_valid, y_valid)))\n",
    "y_test_pred = model_rf.predict(X_valid)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n",
      "  5%|▌         | 1/20 [00:03<01:11,  3.75s/trial, best loss: -0.7672135159429093]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 3/20 [00:14<01:20,  4.72s/trial, best loss: -0.7747269034654849]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 5/20 [00:25<01:09,  4.66s/trial, best loss: -0.7747269034654849]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 30%|███       | 6/20 [00:33<01:21,  5.79s/trial, best loss: -0.7779352633753049]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 9/20 [00:43<00:40,  3.68s/trial, best loss: -0.7793513854829578]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 11/20 [00:52<00:35,  3.91s/trial, best loss: -0.7816508413347666]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 13/20 [01:02<00:27,  3.99s/trial, best loss: -0.7860879406542405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 14/20 [01:10<00:31,  5.18s/trial, best loss: -0.7860879406542405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 16/20 [01:19<00:18,  4.61s/trial, best loss: -0.7860879406542405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 17/20 [01:27<00:16,  5.60s/trial, best loss: -0.7860879406542405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 18/20 [01:35<00:12,  6.33s/trial, best loss: -0.7860879406542405]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:44<00:00,  5.23s/trial, best loss: -0.7860879406542405]\n",
      "Наилучшие значения гиперпараметров {'LR_C': 0.08175332859022828, 'solver': 1}\n",
      "f1_score на обучающем наборе: 0.85\n",
      "accuracy на валидационном наборе: 0.76\n",
      "f1_score на валидационном наборе: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# зафксируем random_state\n",
    "random_state = 42\n",
    "def hyperopt_lr(params, cv=5, X=X_train, y=y_train, random_state=random_state):\n",
    "    # функция получает комбинацию гиперпараметров в \"params\"\n",
    "    params = {'C': float(params['C']),\n",
    "       'solver': str(params['solver'])\n",
    "              }\n",
    "  \n",
    "    # используем эту комбинацию для построения модели\n",
    "    model = linear_model.LogisticRegression(**params, random_state=random_state)\n",
    "\n",
    "    # обучаем модель\n",
    "    model.fit(X, y)\n",
    "    score = metrics.f1_score(y, model.predict(X))\n",
    "    \n",
    "    # кросс-валидация\n",
    "    # применим  cross validation с тем же количеством фолдов\n",
    "    score = cross_val_score(model, X, y, cv=cv, scoring=\"f1\", n_jobs=-1).mean()\n",
    "\n",
    "    # метрику необходимо минимизировать, поэтому ставим знак минус\n",
    "    return -score\n",
    "\n",
    "# начинаем подбор гиперпараметров\n",
    "\n",
    "%time\n",
    "trials = Trials() # используется для логирования результатов\n",
    "\n",
    "best=fmin(hyperopt_lr, # наша функция \n",
    "          space=space_lr, # пространство гиперпараметров\n",
    "          algo=tpe.suggest, # алгоритм оптимизации, установлен по умолчанию, задавать необязательно\n",
    "          max_evals=20, # максимальное количество итераций\n",
    "          trials=trials, # логирование результатов\n",
    "          rstate=np.random.default_rng(random_state)# фиксируем для повторяемости результата\n",
    "         )\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(best))\n",
    "if best['solver'] == 0:\n",
    "    best['solver'] = 'liblinear'\n",
    "else:\n",
    "    best['solver'] ='saga'\n",
    "# рассчитаем точность для тестовой выборки\n",
    "model_rf = linear_model.LogisticRegression(\n",
    "    random_state=random_state, \n",
    "    C=float(best['LR_C']),\n",
    "    solver=best['solver'],\n",
    "    max_iter=30\n",
    ")\n",
    "model_rf.fit(X_train, y_train)\n",
    "y_train_pred = model_rf.predict(X_train)\n",
    "print('f1_score на обучающем наборе: {:.2f}'.format(metrics.f1_score(y_train, y_train_pred)))\n",
    "print(\"accuracy на валидационном наборе: {:.2f}\".format(model_rf.score(X_valid, y_valid)))\n",
    "y_test_pred = model_rf.predict(X_valid)\n",
    "print('f1_score на валидационном наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_test_pred)))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 22:19:27,728]\u001b[0m A new study created in memory with name: RandomForestClassifier\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:19:38,613]\u001b[0m Trial 0 finished with value: 0.9456066945606695 and parameters: {'n_estimators': 112, 'max_depth': 20, 'min_samples_leaf': 5}. Best is trial 0 with value: 0.9456066945606695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:19:52,185]\u001b[0m Trial 1 finished with value: 0.8919402985074627 and parameters: {'n_estimators': 150, 'max_depth': 11, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.9456066945606695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:20:06,084]\u001b[0m Trial 2 finished with value: 0.9206443914081146 and parameters: {'n_estimators': 143, 'max_depth': 17, 'min_samples_leaf': 7}. Best is trial 0 with value: 0.9456066945606695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:20:24,591]\u001b[0m Trial 3 finished with value: 0.9086595492289443 and parameters: {'n_estimators': 198, 'max_depth': 20, 'min_samples_leaf': 9}. Best is trial 0 with value: 0.9456066945606695.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:20:38,074]\u001b[0m Trial 4 finished with value: 0.9912413168227122 and parameters: {'n_estimators': 132, 'max_depth': 22, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:20:49,667]\u001b[0m Trial 5 finished with value: 0.9891304347826088 and parameters: {'n_estimators': 116, 'max_depth': 19, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:21:00,435]\u001b[0m Trial 6 finished with value: 0.9421586165772212 and parameters: {'n_estimators': 111, 'max_depth': 28, 'min_samples_leaf': 5}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:21:17,429]\u001b[0m Trial 7 finished with value: 0.9164933135215453 and parameters: {'n_estimators': 180, 'max_depth': 25, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:21:34,510]\u001b[0m Trial 8 finished with value: 0.9585585585585586 and parameters: {'n_estimators': 174, 'max_depth': 25, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:21:46,546]\u001b[0m Trial 9 finished with value: 0.9131985731272295 and parameters: {'n_estimators': 127, 'max_depth': 30, 'min_samples_leaf': 8}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:21:59,863]\u001b[0m Trial 10 finished with value: 0.9735576923076923 and parameters: {'n_estimators': 134, 'max_depth': 14, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:22:12,229]\u001b[0m Trial 11 finished with value: 0.9894355568970721 and parameters: {'n_estimators': 123, 'max_depth': 23, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:22:24,956]\u001b[0m Trial 12 finished with value: 0.974436090225564 and parameters: {'n_estimators': 128, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:22:35,010]\u001b[0m Trial 13 finished with value: 0.9744668068489035 and parameters: {'n_estimators': 100, 'max_depth': 23, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:22:51,696]\u001b[0m Trial 14 finished with value: 0.9828261524555588 and parameters: {'n_estimators': 165, 'max_depth': 16, 'min_samples_leaf': 2}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:23:05,430]\u001b[0m Trial 15 finished with value: 0.9573829531812725 and parameters: {'n_estimators': 137, 'max_depth': 24, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:23:20,220]\u001b[0m Trial 16 finished with value: 0.9322185727082711 and parameters: {'n_estimators': 153, 'max_depth': 27, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:23:32,384]\u001b[0m Trial 17 finished with value: 0.9714629017723041 and parameters: {'n_estimators': 122, 'max_depth': 21, 'min_samples_leaf': 3}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:23:42,200]\u001b[0m Trial 18 finished with value: 0.950956937799043 and parameters: {'n_estimators': 101, 'max_depth': 17, 'min_samples_leaf': 4}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:23:57,515]\u001b[0m Trial 19 finished with value: 0.9348086124401915 and parameters: {'n_estimators': 161, 'max_depth': 22, 'min_samples_leaf': 6}. Best is trial 4 with value: 0.9912413168227122.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'n_estimators': 132, 'max_depth': 22, 'min_samples_leaf': 2}\n",
      "f1_score на обучающем наборе: 0.99\n",
      "mean f1 score is on cross validation: 0.8151690879348843\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.79\n"
     ]
    }
   ],
   "source": [
    "def optuna_rf(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  n_estimators = trial.suggest_int('n_estimators', 100, 200, 1)\n",
    "  max_depth = trial.suggest_int('max_depth', 10, 30, 1)\n",
    "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 10, 1)\n",
    "\n",
    "  # создаем модель\n",
    "  model = ensemble.RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                          max_depth=max_depth,\n",
    "                                          min_samples_leaf=min_samples_leaf,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "  return score\n",
    "\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_1 = optuna.create_study(study_name=\"RandomForestClassifier\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_1.optimize(optuna_rf, n_trials=20)\n",
    "\n",
    "\n",
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study_1.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study_1.best_value))\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_state)\n",
    "\n",
    "best_params = study_1.best_params\n",
    "f1_train = []\n",
    "f1_valid = []\n",
    "for train_index, valid_index in kf.split(X):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "    model = ensemble.RandomForestClassifier(random_state=random_state,\n",
    "                          **best_params)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "    f1_train.append(metrics.f1_score(y_train, y_train_pred))\n",
    "    f1_valid.append(metrics.f1_score(y_valid, y_valid_pred))\n",
    "f1_train = np.array(f1_train)\n",
    "f1_valid = np.array(f1_valid)\n",
    "print(\"mean f1 score is on cross validation: {}\".format(f1_valid.mean()))\n",
    "\n",
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study_1.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_valid, y_valid)))\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-27 22:27:11,956]\u001b[0m A new study created in memory with name: LogisticRegression\u001b[0m\n",
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-27 22:27:13,260]\u001b[0m Trial 0 finished with value: 0.8610451306413303 and parameters: {'C': 0.6955977683375537, 'solver': 'saga'}. Best is trial 0 with value: 0.8610451306413303.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:13,669]\u001b[0m Trial 1 finished with value: 0.881508078994614 and parameters: {'C': 0.536018828751838, 'solver': 'liblinear'}. Best is trial 1 with value: 0.881508078994614.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:14,068]\u001b[0m Trial 2 finished with value: 0.883428228948157 and parameters: {'C': 0.5778909318194105, 'solver': 'liblinear'}. Best is trial 2 with value: 0.883428228948157.\u001b[0m\n",
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-27 22:27:15,370]\u001b[0m Trial 3 finished with value: 0.8596022558622737 and parameters: {'C': 0.473802361102198, 'solver': 'saga'}. Best is trial 2 with value: 0.883428228948157.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:15,792]\u001b[0m Trial 4 finished with value: 0.8813863161039737 and parameters: {'C': 0.49628248848264755, 'solver': 'liblinear'}. Best is trial 2 with value: 0.883428228948157.\u001b[0m\n",
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-27 22:27:17,088]\u001b[0m Trial 5 finished with value: 0.8494687131050768 and parameters: {'C': 0.09160564950817907, 'solver': 'saga'}. Best is trial 2 with value: 0.883428228948157.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:17,500]\u001b[0m Trial 6 finished with value: 0.8807887660591575 and parameters: {'C': 0.4832270000066534, 'solver': 'liblinear'}. Best is trial 2 with value: 0.883428228948157.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:17,913]\u001b[0m Trial 7 finished with value: 0.8866906474820144 and parameters: {'C': 0.6721604814224377, 'solver': 'liblinear'}. Best is trial 7 with value: 0.8866906474820144.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:18,320]\u001b[0m Trial 8 finished with value: 0.8860227954409118 and parameters: {'C': 0.6121162442553311, 'solver': 'liblinear'}. Best is trial 7 with value: 0.8866906474820144.\u001b[0m\n",
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-27 22:27:19,614]\u001b[0m Trial 9 finished with value: 0.8600237247924081 and parameters: {'C': 0.5884690026277485, 'solver': 'saga'}. Best is trial 7 with value: 0.8866906474820144.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:20,126]\u001b[0m Trial 10 finished with value: 0.8902877697841728 and parameters: {'C': 0.9568547904645942, 'solver': 'liblinear'}. Best is trial 10 with value: 0.8902877697841728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:20,595]\u001b[0m Trial 11 finished with value: 0.8902877697841728 and parameters: {'C': 0.9661533942534287, 'solver': 'liblinear'}. Best is trial 10 with value: 0.8902877697841728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:21,059]\u001b[0m Trial 12 finished with value: 0.8902877697841728 and parameters: {'C': 0.9594476788628049, 'solver': 'liblinear'}. Best is trial 10 with value: 0.8902877697841728.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:21,564]\u001b[0m Trial 13 finished with value: 0.8906203176505842 and parameters: {'C': 0.9879047702092318, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:22,077]\u001b[0m Trial 14 finished with value: 0.8906203176505842 and parameters: {'C': 0.9893445513516075, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:22,579]\u001b[0m Trial 15 finished with value: 0.8890887290167866 and parameters: {'C': 0.8492203677471999, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:23,024]\u001b[0m Trial 16 finished with value: 0.8890887290167866 and parameters: {'C': 0.8464845093621562, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:23,473]\u001b[0m Trial 17 finished with value: 0.8884892086330937 and parameters: {'C': 0.7820918400516149, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "c:\\Users\\Павел\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2023-04-27 22:27:24,769]\u001b[0m Trial 18 finished with value: 0.861812778603269 and parameters: {'C': 0.9896996413029824, 'solver': 'saga'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n",
      "\u001b[32m[I 2023-04-27 22:27:25,223]\u001b[0m Trial 19 finished with value: 0.8890887290167866 and parameters: {'C': 0.8479759291024085, 'solver': 'liblinear'}. Best is trial 13 with value: 0.8906203176505842.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наилучшие значения гиперпараметров {'C': 0.9879047702092318, 'solver': 'liblinear'}\n",
      "f1_score на обучающем наборе: 0.89\n",
      "accuracy на тестовом наборе: 0.78\n",
      "f1_score на тестовом наборе: 0.79\n"
     ]
    }
   ],
   "source": [
    "def optuna_lr(trial):\n",
    "  # задаем пространства поиска гиперпараметров\n",
    "  C = trial.suggest_float('C', 0, 1)\n",
    "  solver = trial.suggest_categorical('solver', ['liblinear', 'saga'])\n",
    "  \n",
    "\n",
    "  # создаем модель\n",
    "  model = linear_model.LogisticRegression(C=C,\n",
    "                                          solver=solver,\n",
    "                                          max_iter=30,\n",
    "                                          random_state=random_state)\n",
    "  # обучаем модель\n",
    "  model.fit(X_train, y_train)\n",
    "  score = metrics.f1_score(y_train, model.predict(X_train))\n",
    "\n",
    "  return score\n",
    "\n",
    "# можем напрямую указать, что нам необходимо максимизировать метрику direction=\"maximize\"\n",
    "study_2 = optuna.create_study(study_name=\"LogisticRegression\", direction=\"maximize\")\n",
    "# ищем лучшую комбинацию гиперпараметров n_trials раз\n",
    "study_2.optimize(optuna_lr, n_trials=20)\n",
    "\n",
    "# выводим результаты на обучающей выборке\n",
    "print(\"Наилучшие значения гиперпараметров {}\".format(study_2.best_params))\n",
    "print(\"f1_score на обучающем наборе: {:.2f}\".format(study_2.best_value))\n",
    "\n",
    "# рассчитаем точность для тестовой выборки\n",
    "model = ensemble.RandomForestClassifier(**study_1.best_params,random_state=random_state, )\n",
    "model.fit(X_train, y_train)\n",
    "y_train_pred = model.predict(X_train)\n",
    "print(\"accuracy на тестовом наборе: {:.2f}\".format(model.score(X_valid, y_valid)))\n",
    "y_valid_pred = model.predict(X_valid)\n",
    "print('f1_score на тестовом наборе: {:.2f}'.format(metrics.f1_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изходя из полученных результатов можно сделать вывод что метод случайного леса на продвинутых методах переобучается, следовательно нужно тчательнее подойти к выборам параметров, то есть поиграть с диапозонома"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
